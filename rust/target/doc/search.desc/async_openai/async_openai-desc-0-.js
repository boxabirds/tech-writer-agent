searchState.loadedDescShard("async_openai", 0, "Rust library for OpenAI\nFiles attached to an assistant.\nBuild assistants that can call models and use tools to …\nTurn audio into text Related guide: Speech to text\nGiven a list of messages comprising a conversation, the …\nClient is a container for config, backoff and http_client …\nGiven a prompt, the model will return one or more …\nGiven a prompt and an instruction, the model will return …\nGet a vector representation of a given input that can be …\nFiles are used to upload documents that can be used with …\nManage fine-tuning jobs to tailor a model to your specific …\nManage fine-tuning jobs to tailor a model to your specific …\nGiven a prompt and/or an input image, the model will …\nFiles attached to a message.\nRepresents a message within a thread.\nList and describe the various models available in the API. …\nGiven a input text, outputs if the model classifies it as …\nRepresents an execution run on a thread.\nRepresents a step in execution of a run.\nCreate threads that assistants can interact with.\nTo call Assistants group related APIs using this client.\nTo call Audio group related APIs using this client.\nImmediately cancel a fine-tune job.\nImmediately cancel a fine-tune job.\nCancels a run that is <code>in_progress</code>\nTo call Chat group related APIs using this client.\nTo call Completions group related APIs using this client.\nClient configurations: OpenAIConfig for OpenAI, AzureConfig…\nCreate an assistant file by attaching a File to an …\nCreate an assistant with a model and instructions.\nCreates a model response for the given chat conversation.\nCreates a completion for the provided prompt and parameters\nCreates a new edit for the provided input, instruction, …\nCreates an embedding vector representing the input text.\nUpload a file that contains document(s) to be used across …\nCreates a job that fine-tunes a specified model from a …\nCreates a job that fine-tunes a specified model from a …\nCreates an image given a prompt.\nCreate a message.\nClassifies if text violates OpenAI’s Content Policy\nCreate a run.\nCreate a thread.\nCreate a thread and run it in one request.\nCreates an edited or extended image given an original …\nCreates a completion for the chat message\nCreates a completion request for the provided prompt and …\nCreates a variation of a given image.\nDelete an assistant file.\nDelete an assistant.\nDelete a file.\nDelete a fine-tuned model. You must have the Owner role in …\nDelete a thread.\nTo call Edits group related APIs using this client.\nTo call Embeddings group related APIs using this client.\nErrors originating from API calls, parsing responses, and …\nAssistant AssistantFiles API group\nCall MessageFiles API group\nTo call Files group related APIs using this client.\nTo call FineTunes group related APIs using this client.\nTo call FineTuning group related APIs using this client.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nTo call Images group related APIs using this client.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns a list of assistant files.\nReturns a list of assistants.\nReturns a list of files that belong to the user’s …\nList your organization’s fine-tuning jobs\nReturns a list of message files.\nReturns a list of messages for a given thread.\nLists the currently available models, and provides basic …\nReturns a list of runs belonging to a thread.\nReturns a list of run steps belonging to a run.\nGet fine-grained status updates for a fine-tune job.\nGet fine-grained status updates for a fine-tune job.\nGet fine-grained status updates for a fine-tune job.\nList your organization’s fine-tuning jobs\nCall Messages group API to manage message in [thread_id] …\nTo call Models group related APIs using this client.\nTo call Moderations group related APIs using this client.\nClient with default OpenAIConfig\nRetrieves an AssistantFile.\nRetrieves an assistant.\nReturns information about a specific file.\nGets info about the fine-tune job.\nGets info about the fine-tune job.\nRetrieves a message file.\nRetrieve a message.\nRetrieves a model instance, providing basic information …\nRetrieves a run.\nRetrieves a run step.\nRetrieves a thread.\nReturns the contents of the specified file\nCall Runs group API to manage runs in [thread_id] thread.\nGenerates audio from the input text.\nSteps API group\nWhen a run has the status: “requires_action” and …\nThe ID of the thread to create a message for.\nTo call Threads group related APIs using this client.\nTranscribes audio into the input language.\nTranslates audio into into English.\nTypes used in OpenAI API requests and responses. These …\nModifies an assistant.\nModifies a message.\nModifies a run.\nModifies a thread.\nExponential backoff for retrying rate limited requests.\nCreate client with OpenAIConfig or …\nProvide your own client to make HTTP requests with.\nConfiguration for Azure OpenAI Service\ncrate::Client relies on this for every API call on OpenAI …\nDefault v1 API base url\nCalls to the Assistants API require that you pass a Beta …\nName for organization header\nConfiguration for OpenAI API\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate client with default OPENAI_API_BASE url and default …\nTo use a API base url different from default …\nAPI base url in form of …\nTo use a different API key different from default …\nTo use a different API key different from default …\nTo use a different organization id other than default\nOpenAI API returns error object on failure\nOpenAI returns error object with details of API call …\nError on the client side when reading file from file system\nError on the client side when saving file to file system\nError from client side validation or when builder fails to …\nError when a response cannot be deserialized into a Rust …\nUnderlying error from reqwest library after an API call …\nError on SSE streaming\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nAn array of content parts with a defined type, each can be …\nA list of Files attached to an <code>assistant</code>.\nRepresents an <code>assistant</code> that can call the model and use …\nCode interpreter tool\nFunction tool\nRetrieval tool\nThe model can pick between an end-user or calling a …\nThe base64-encoded JSON of the generated image, if …\nA list of the categories along with their scores as …\nBuilder for <code>ChatCompletionFunctions</code>.\nSpecifies a tool the model should use. Use to force the …\nBuilder for <code>ChatCompletionRequestAssistantMessage</code>.\nBuilder for <code>ChatCompletionRequestFunctionMessage</code>.\nBuilder for <code>ChatCompletionRequestMessageContentPartImage</code>.\nBuilder for <code>ChatCompletionRequestMessageContentPartText</code>.\nBuilder for <code>ChatCompletionRequestSystemMessage</code>.\nTool message\nBuilder for <code>ChatCompletionRequestToolMessage</code>.\nBuilder for <code>ChatCompletionRequestUserMessage</code>.\nA chat completion message generated by the model.\nParsed server side events stream until an [DONE] is …\nA chat completion delta generated by streamed model …\nBuilder for <code>ChatCompletionTool</code>.\nControls which (if any) function is called by the model. …\nDetails of the Code Interpreter tool call the run step was …\nParsed server side events stream until an [DONE] is …\nUsage statistics for the completion request.\nBuilder for <code>CreateAssistantRequest</code>.\nBuilder for <code>CreateChatCompletionRequest</code>.\nRepresents a chat completion response returned by model, …\nRepresents a streamed chunk of a chat completion response …\nBuilder for <code>CreateCompletionRequest</code>.\nBuilder for <code>CreateEditRequest</code>.\nBuilder for <code>CreateEmbeddingRequest</code>.\nBuilder for <code>CreateFileRequest</code>.\nBuilder for <code>CreateFineTuneRequest</code>.\nBuilder for <code>CreateFineTuningJobRequest</code>.\nBuilder for <code>CreateImageEditRequest</code>.\nBuilder for <code>CreateImageRequest</code>.\nBuilder for <code>CreateImageVariationRequest</code>.\nBuilder for <code>CreateMessageRequest</code>.\nBuilder for <code>CreateModerationRequest</code>.\nRepresents policy compliance report by OpenAI’s content …\nBuilder for <code>CreateRunRequest</code>.\nBuilder for <code>CreateSpeechRequest</code>.\nBuilder for <code>CreateThreadAndRunRequest</code>.\nBuilder for <code>CreateThreadRequest</code>.\nBuilder for <code>CreateTranscriptionRequest</code>.\nBuilder for <code>CreateTranslationRequest</code>.\nDeletes the association between the assistant and the …\nRepresents an embedding vector returned by embedding …\nA citation within the message that points to a specific …\nA URL for the file that’s generated when the assistant …\nParsed server side events stream until an [DONE] is …\nFor fine-tuning jobs that have <code>failed</code>, this will contain …\nThe <code>fine_tuning.job</code> object represents a fine-tuning job …\nFine-tuning job event object\nForces the model to call the specified function.\nThe name and arguments of a function that should be …\nCode interpreter image output\nBuilder for <code>ImageUrl</code>.\nCode interpreter log output\nReferences an image File in the content of a message.\nThe text content that is part of a message.\nA list of files attached to a <code>message</code>.\nRepresents a message within a thread.\nDescribes an OpenAI model offering that can be used with …\nBuilder for <code>ModifyAssistantRequest</code>.\nThe model does not call a function, and responds to the …\nThe <code>File</code> object represents a document that has been …\nRepresents an execution run on a thread.\nDetails of the message creation by the run step.\nCode interpreter tool call\nText output from the Code Interpreter tool call as part of …\nDetails of the tool call.\nRepresents a step in execution of a run.\nThe text contents of the message.\nRepresents a thread that contains messages.\nBuilder for <code>ToolsOutputs</code>.\nThe URL of the generated image, if <code>response_format</code> is <code>url</code> …\nThe arguments passed to the function.\nThe arguments to call the function with, as generated by …\nThe arguments to call the function with, as generated by …\nThe ID of the assistant to use to execute this run.\nThe ID of the assistant to use to execute this run.\nThe assistant ID that the file is attached to.\nIf applicable, the ID of the assistant that authored this …\nThe ID of the assistant used for execution of this run.\nThe ID of the assistant to use to execute this run.\nThe ID of the assistant associated with the run step.\nThe ID of the assistant to use to execute this run.\nThe batch size to use for training. The batch size is the …\nThe batch size to use for training. The batch size is the …\nGenerates <code>best_of</code> completions server-side and returns the …\nGenerates <code>best_of</code> completions server-side and returns the …\nBuilds a new <code>CreateAssistantRequest</code>.\nBuilds a new <code>ModifyAssistantRequest</code>.\nBuilds a new <code>CreateMessageRequest</code>.\nBuilds a new <code>CreateRunRequest</code>.\nBuilds a new <code>ToolsOutputs</code>.\nBuilds a new <code>CreateThreadRequest</code>.\nBuilds a new <code>CreateThreadAndRunRequest</code>.\nBuilds a new <code>CreateCompletionRequest</code>.\nBuilds a new <code>CreateEditRequest</code>.\nBuilds a new <code>CreateImageRequest</code>.\nBuilds a new <code>CreateImageEditRequest</code>.\nBuilds a new <code>CreateImageVariationRequest</code>.\nBuilds a new <code>CreateModerationRequest</code>.\nBuilds a new <code>CreateFileRequest</code>.\nBuilds a new <code>CreateFineTuneRequest</code>.\nBuilds a new <code>CreateFineTuningJobRequest</code>.\nBuilds a new <code>CreateEmbeddingRequest</code>.\nBuilds a new <code>ChatCompletionRequestSystemMessage</code>.\nBuilds a new <code>ChatCompletionRequestMessageContentPartText</code>.\nBuilds a new <code>ImageUrl</code>.\nBuilds a new <code>ChatCompletionRequestMessageContentPartImage</code>.\nBuilds a new <code>ChatCompletionRequestUserMessage</code>.\nBuilds a new <code>ChatCompletionRequestAssistantMessage</code>.\nBuilds a new <code>ChatCompletionRequestToolMessage</code>.\nBuilds a new <code>ChatCompletionRequestFunctionMessage</code>.\nBuilds a new <code>ChatCompletionFunctions</code>.\nBuilds a new <code>ChatCompletionTool</code>.\nBuilds a new <code>CreateChatCompletionRequest</code>.\nBuilds a new <code>CreateTranscriptionRequest</code>.\nBuilds a new <code>CreateSpeechRequest</code>.\nBuilds a new <code>CreateTranslationRequest</code>.\nThe size of the file in bytes.\nThe Unix timestamp (in seconds) for when the run was …\nThe Unix timestamp (in seconds) for when the run step was …\nA list of the categories, and whether they are flagged or …\nA list of the categories along with their scores as …\nA list of chat completion choices. Can be more than one if …\nA list of chat completion choices. Can be more than one if …\nIf this is provided, we calculate F-beta scores at the …\nIf this is provided, we calculate F-beta scores at the …\nThe number of classes in a classification task.\nThe number of classes in a classification task.\nThe positive class in binary classification.\nThe positive class in binary classification.\nOne of <code>server_error</code> or <code>rate_limit_exceeded</code>.\nA machine-readable error code.\nThe Code Interpreter tool call definition.\nThe Unix timestamp (in seconds) for when the run was …\nThe Unix timestamp (in seconds) for when the run step …\nNumber of tokens in the generated completion.\nIf set, we calculate classification-specific metrics such …\nIf set, we calculate classification-specific metrics such …\nThe content of the message.\nThe contents of the system message.\nThe contents of the user message.\nThe contents of the assistant message.\nThe contents of the tool message.\nThe return value from the function call, to return to the …\nThe content of the message in array of text and/or images.\nThe content of the message.\nThe contents of the system message.\nThe contents of the user message.\nThe contents of the assistant message.\nThe contents of the tool message.\nThe return value from the function call, to return to the …\nThe contents of the message.\nThe contents of the chunk message.\nThe Unix timestamp (in seconds) when the model was created.\nThe Unix timestamp (in seconds) of when the completion was …\nThe Unix timestamp (in seconds) of when the chat …\nThe Unix timestamp (in seconds) of when the chat …\nThe Unix timestamp (in seconds) for when the assistant was …\nThe Unix timestamp (in seconds) for when the assistant …\nThe Unix timestamp (in seconds) for when the message was …\nThe Unix timestamp (in seconds) for when the message file …\nThe Unix timestamp (in seconds) for when the run was …\nThe Unix timestamp (in seconds) for when the run step was …\nThe Unix timestamp (in seconds) for when the thread was …\nThe Unix timestamp (in seconds) for when the file was …\nThe Unix timestamp (in seconds) for when the fine-tuning …\nThe list of embeddings generated by the model.\nA description of what the function does, used by the model …\nThe description of the assistant. The maximum length is …\nA description of what the function does, used by the model …\nSpecifies the detail level of the image.\nSpecifies the detail level of the image.\nEcho back the prompt in addition to the completion\nEcho back the prompt in addition to the completion\nThe embedding vector, which is a list of floats. The …\nThe format to return the embeddings in. Can be either <code>float</code>…\nThe format to return the embeddings in. Can be either <code>float</code>…\nFor fine-tuning jobs that have <code>failed</code>, this will contain …\nThe Unix timestamp (in seconds) for when the run step …\nThe Unix timestamp (in seconds) for when the run will …\nThe Unix timestamp (in seconds) for when the run failed.\nThe Unix timestamp (in seconds) for when the run step …\nThe file object to be uploaded.\nThe audio file to transcribe, in one of these formats: …\nThe audio file to transcribe, in one of these formats: …\nThe file object to be uploaded.\nThe audio file to transcribe, in one of these formats: …\nThe audio file to transcribe, in one of these formats: …\nA File ID (with <code>purpose=&quot;assistants&quot;</code>) that the assistant …\nThe ID of the specific File the citation is from.\nThe ID of the file that was generated.\nThe File ID of the image in the message content.\nA list of File IDs that the message should use. There can …\nA list of file IDs attached to this assistant. There can …\nA list of file IDs that the assistant should use. Useful …\nA list of File IDs that the message should use. There can …\nThe list of File IDs the assistant used for this run.\nThe name of the file.\nThe name of the fine-tuned model that is being created. …\nThe reason the model stopped generating tokens. This will …\nThe Unix timestamp (in seconds) for when the fine-tuning …\nWhether the content violates OpenAI’s usage policies.\nNumber between -2.0 and 2.0. Positive values penalize new …\nNumber between -2.0 and 2.0. Positive values penalize new …\nNumber between -2.0 and 2.0. Positive values penalize new …\nNumber between -2.0 and 2.0. Positive values penalize new …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe function definition.\nhe definition of the function that was called.\nThe function that the model called.\nDeprecated and replaced by <code>tool_calls</code>. The name and …\nControls how the model responds to function calls. “none…\nDeprecated and replaced by <code>tool_calls</code>. The name and …\nDeprecated and replaced by <code>tool_calls</code>. The name and …\nControls how the model responds to function calls. “none…\nThe name and arguments of a function that should be …\nA list of functions the model may generate JSON inputs for.\nA list of functions the model may generate JSON inputs for.\nContent that expresses, incites, or promotes harassing …\nThe score for the category ‘harassment’.\nHarassment content that also includes violence or serious …\nThe score for the category ‘harassment/threatening’.\nContent that expresses, incites, or promotes hate based on …\nThe score for the category ‘hate’.\nHateful content that also includes violence or serious …\nThe score for the category ‘hate/threatening’.\nThe hyperparameters used for the fine-tuning job.\nThe hyperparameters used for the fine-tuning job.\nThe hyperparameters used for the fine-tuning job. See the …\nThe identifier, which can be referenced in API endpoints.\nThe identifier, which can be referenced in API endpoints.\nThe identifier, which can be referenced in API endpoints.\nThe identifier, which can be referenced in API endpoints.\nThe identifier, which can be referenced in API endpoints.\nThe ID of the tool call. This ID must be referenced when …\nThe identifier, which can be referenced in API endpoints.\nThe ID of the tool call.\nThe ID of the tool call object.\nThe ID of the tool call object.\nThe identifier, which can be referenced in API endpoints.\nThe model identifier, which can be referenced in the API …\nA unique identifier for the completion.\nThe unique identifier for the moderation request.\nThe file identifier, which can be referenced in the API …\nThe object identifier, which can be referenced in the API …\nThe ID of the tool call.\nA unique identifier for the chat completion.\nThe ID of the tool call.\nA unique identifier for the chat completion. Each chunk …\nThe image to edit. Must be a valid PNG file, less than …\nThe image to use as the basis for the variation(s). Must …\nThe file ID of the image.\nThe image to edit. Must be a valid PNG file, less than …\nThe image to use as the basis for the variation(s). Must …\nThe index of the embedding in the list of embeddings.\nThe index of the choice in the list of choices.\nThe index of the choice in the list of choices.\nThe input text to use as a starting point for the edit.\nThe input text to classify\nInput text to embed, encoded as a string or array of …\nThe text to generate audio for. The maximum length is 4096 …\nThe input to the Code Interpreter tool call.\nThe input text to use as a starting point for the edit.\nThe input text to classify\nInput text to embed, encoded as a string or array of …\nThe text to generate audio for. The maximum length is 4096 …\nThe instruction that tells the model how to edit the …\nThe instruction that tells the model how to edit the …\nOverride the default system message of the assistant. This …\nOverride the default system message of the assistant. This …\nThe system instructions that the assistant uses. The …\nThe instructions that the assistant used for this run.\nOverride the default system message of the assistant. This …\nOverride the default system message of the assistant. This …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe language of the input audio. Supplying the input …\nThe language of the input audio. Supplying the input …\nThe last error associated with this run. Will be <code>null</code> if …\nThe last error associated with this run. Will be <code>null</code> if …\nThe learning rate multiplier to use for training. The …\nThe learning rate multiplier to use for training. The …\nModify the likelihood of specified tokens appearing in the …\nModify the likelihood of specified tokens appearing in the …\nModify the likelihood of specified tokens appearing in the …\nModify the likelihood of specified tokens appearing in the …\nInclude the log probabilities on the <code>logprobs</code> most likely …\nInclude the log probabilities on the <code>logprobs</code> most likely …\nThe text output from the Code Interpreter tool call.\nAn additional image whose fully transparent areas (e.g. …\nAn additional image whose fully transparent areas (e.g. …\nThe maximum number of tokens to generate in the completion.\nThe maximum number of tokens to generate in the chat …\nThe maximum number of tokens to generate in the completion.\nThe maximum number of tokens to generate in the chat …\nA human-readable description of the error.\nA human-readable error message.\nThe ID of the message that the File is attached to.\nThe ID of the message that was created by this run step.\nA list of messages to start the thread with.\nA list of messages comprising the conversation so far. …\nA list of messages to start the thread with.\nA list of messages comprising the conversation so far. …\nThe ID of the Model to be used to execute this run. If a …\nThe ID of the Model to be used to execute this run. If a …\nID of the model to use. You can use the List models API to …\nID of the model to use. You can use the …\nThe model to use for image generation.\nThe model to use for image generation. Only <code>dall-e-2</code> is …\nThe model to use for image generation. Only <code>dall-e-2</code> is …\nTwo content moderations models are available: …\nThe name of the base model to fine-tune. You can select …\nThe name of the model to fine-tune. You can select one of …\nID of the model to use. You can use the List models API to …\nID of the model to use. See the model endpoint …\nID of the model to use. Only <code>whisper-1</code> is currently …\nOne of the available TTS models: <code>tts-1</code> or <code>tts-1-hd</code>\nID of the model to use. Only <code>whisper-1</code> is currently …\nThe model that the assistant used for this run.\nThe ID of the Model to be used to execute this run. If a …\nThe ID of the Model to be used to execute this run. If a …\nID of the model to use. You can use the List models API to …\nThe model used for completion.\nID of the model to use. You can use the …\nThe model to use for image generation.\nThe model to use for image generation. Only <code>dall-e-2</code> is …\nThe model to use for image generation. Only <code>dall-e-2</code> is …\nTwo content moderations models are available: …\nThe model used to generate the moderation results.\nThe name of the base model to fine-tune. You can select …\nThe name of the model to fine-tune. You can select one of …\nThe base model that is being fine-tuned.\nID of the model to use. You can use the List models API to …\nThe name of the model used to generate the embedding.\nID of the model to use. See the model endpoint …\nThe model used for the chat completion.\nThe model to generate the completion.\nID of the model to use. Only <code>whisper-1</code> is currently …\nOne of the available TTS models: <code>tts-1</code> or <code>tts-1-hd</code>\nID of the model to use. Only <code>whisper-1</code> is currently …\nHow many completions to generate for each prompt. <strong>Note:</strong> …\nHow many edits to generate for the input and instruction.\nThe number of images to generate. Must be between 1 and …\nThe number of images to generate. Must be between 1 and 10.\nThe number of images to generate. Must be between 1 and 10.\nHow many chat completion choices to generate for each …\nHow many completions to generate for each prompt. <strong>Note:</strong> …\nHow many edits to generate for the input and instruction.\nThe number of images to generate. Must be between 1 and …\nThe number of images to generate. Must be between 1 and 10.\nThe number of images to generate. Must be between 1 and 10.\nHow many chat completion choices to generate for each …\nThe number of epochs to train the model for. An epoch …\nThe number of epochs to train the model for. An epoch …\nThe number of epochs to train the model for. An epoch …\nThe name of the function to call.\nThe name of the function to be called. Must be a-z, A-Z, …\nThe name of the assistant. The maximum length is 256 …\nThe name of the function.\nThe name of the function to call.\nThe name of the function to call.\nThe name of the function to be called. Must be a-z, A-Z, …\nThe name of the function to call.\nThe name of the function to call.\nThe object type, which is always <code>assistant</code>.\nThe object type, which is always <code>assistant.file</code>.\nThe object type, which is always <code>thread.message</code>.\nThe object type, which is always <code>thread.message.file</code>.\nThe object type, which is always <code>thread.run</code>.\nThe object type, which is always <code>thread.run.step</code>.\nThe object type, which is always <code>thread</code>.\nThe object type, which is always “model”.\nThe object type, which is always “text_completion”\nThe object type, which is always “file”.\nThe object type, which is always “fine_tuning.job”.\nThe object type, which is always “embedding”.\nThe object type, which is always <code>chat.completion</code>.\nThe object type, which is always <code>chat.completion.chunk</code>.\nThe organization that owns the fine-tuning job.\nThe output of the tool call to be submitted to continue …\nThe output of the tool call to be submitted to continue …\nThe output of the function. This will be <code>null</code> if the …\nThe outputs from the Code Interpreter tool call. Code …\nThe organization that owns the model.\nThe parameter that was invalid, usually <code>training_file</code> or …\nThe parameters the functions accepts, described as a JSON …\nThe parameters the functions accepts, described as a JSON …\nNumber between -2.0 and 2.0. Positive values penalize new …\nNumber between -2.0 and 2.0. Positive values penalize new …\nNumber between -2.0 and 2.0. Positive values penalize new …\nNumber between -2.0 and 2.0. Positive values penalize new …\nThe prompt(s) to generate completions for, encoded as a …\nA text description of the desired image(s). The maximum …\nA text description of the desired image(s). The maximum …\nAn optional text to guide the model’s style or continue …\nAn optional text to guide the model’s style or continue …\nThe prompt(s) to generate completions for, encoded as a …\nA text description of the desired image(s). The maximum …\nA text description of the desired image(s). The maximum …\nAn optional text to guide the model’s style or continue …\nAn optional text to guide the model’s style or continue …\nThe weight to use for loss on the prompt tokens. This …\nThe weight to use for loss on the prompt tokens. This …\nNumber of tokens in the prompt.\nThe number of tokens used by the prompt.\nThe intended purpose of the uploaded file.\nThe intended purpose of the uploaded file.\nThe intended purpose of the file. Supported values are …\nThe quality of the image that will be generated. <code>hd</code> …\nThe quality of the image that will be generated. <code>hd</code> …\nThe specific quote in the file.\nDetails on the action required to continue the run. Will …\nThe format in which the generated images are returned. …\nThe format in which the generated images are returned. …\nThe format in which the generated images are returned. …\nAn object specifying the format that the model must output.\nThe format of the transcript output, in one of these …\nThe format to audio in. Supported formats are mp3, opus, …\nThe format of the transcript output, in one of these …\nThe format in which the generated images are returned. …\nThe format in which the generated images are returned. …\nThe format in which the generated images are returned. …\nAn object specifying the format that the model must output.\nThe format of the transcript output, in one of these …\nThe format to audio in. Supported formats are mp3, opus, …\nThe format of the transcript output, in one of these …\nThe compiled results file ID(s) for the fine-tuning job. …\nA list of moderation objects.\nFor now, this is always going to be an empty object.\nThe role of the entity that is creating the message. …\nThe role of the messages author, in this case <code>system</code>.\nThe role of the messages author, in this case <code>user</code>.\nThe role of the messages author, in this case <code>assistant</code>.\nThe role of the messages author, in this case <code>tool</code>.\nThe role of the messages author, in this case <code>function</code>.\nThe entity that produced the message. One of <code>user</code> or …\nThe role of the entity that is creating the message. …\nThe role of the messages author, in this case <code>system</code>.\nThe role of the messages author, in this case <code>user</code>.\nThe role of the messages author, in this case <code>assistant</code>.\nThe role of the messages author, in this case <code>tool</code>.\nThe role of the messages author, in this case <code>function</code>.\nThe role of the author of this message.\nThe role of the author of this message.\nIf applicable, the ID of the run associated with the …\nThe ID of the run that this run step is a part of.\nSave each image in a dedicated Tokio task and return paths …\nIf specified, our system will make a best effort to sample …\nThis feature is in Beta. If specified, our system will …\nIf specified, our system will make a best effort to sample …\nThis feature is in Beta. If specified, our system will …\nContent that promotes, encourages, or depicts acts of …\nThe score for the category ‘self-harm’.\nContent that encourages performing acts of self-harm, such …\nThe score for the category ‘self-harm/instructions’.\nContent where the speaker expresses that they are engaging …\nThe score for the category ‘self-harm/intent’.\nContent meant to arouse sexual excitement, such as the …\nThe score for the category ‘sexual’.\nSexual content that includes an individual who is under 18 …\nThe score for the category ‘sexual/minors’.\nThe size of the generated images. Must be one of <code>256x256</code>, …\nThe size of the generated images. Must be one of <code>256x256</code>, …\nThe size of the generated images. Must be one of <code>256x256</code>, …\nThe size of the generated images. Must be one of <code>256x256</code>, …\nThe size of the generated images. Must be one of <code>256x256</code>, …\nThe size of the generated images. Must be one of <code>256x256</code>, …\nThe speed of the generated audio. Select a value from 0.25 …\nThe speed of the generated audio. Select a value from 0.25 …\nThe Unix timestamp (in seconds) for when the run was …\nThe status of the run, which can be either <code>queued</code>, …\nThe status of the run step, which can be either <code>in_progress</code>…\nDeprecated. The current status of the file, which can be …\nThe current status of the fine-tuning job, which can be …\nDeprecated. For details on why a fine-tuning training file …\nThe details of the run step.\nUp to 4 sequences where the API will stop generating …\nUp to 4 sequences where the API will stop generating …\nUp to 4 sequences where the API will stop generating …\nUp to 4 sequences where the API will stop generating …\nWhether to stream back partial progress. If set, tokens …\nIf set, partial message deltas will be sent, like in …\nWhether to stream back partial progress. If set, tokens …\nIf set, partial message deltas will be sent, like in …\nThe style of the generated images. Must be one of <code>vivid</code> or …\nThe style of the generated images. Must be one of <code>vivid</code> or …\nThe suffix that comes after a completion of inserted text.\nA string of up to 40 characters that will be added to your …\nA string of up to 18 characters that will be added to your …\nThe suffix that comes after a completion of inserted text.\nA string of up to 40 characters that will be added to your …\nA string of up to 18 characters that will be added to your …\nThis fingerprint represents the backend configuration that …\nThis fingerprint represents the backend configuration that …\nThis fingerprint represents the backend configuration that …\nWhat sampling temperature to use, between 0 and 2. Higher …\nWhat sampling temperature to use. Higher values means the …\nWhat sampling temperature to use, between 0 and 2. Higher …\nThe sampling temperature, between 0 and 1. Higher values …\nThe sampling temperature, between 0 and 1. Higher values …\nWhat sampling temperature to use, between 0 and 2. Higher …\nWhat sampling temperature to use. Higher values means the …\nWhat sampling temperature to use, between 0 and 2. Higher …\nThe sampling temperature, between 0 and 1. Higher values …\nThe sampling temperature, between 0 and 1. Higher values …\nThe text in the message content that needs to be replaced.\nThe text in the message content that needs to be replaced.\nIf no thread is provided, an empty thread will be created.\nIf no thread is provided, an empty thread will be created.\nThe thread ID that this message belongs to.\nThe ID of the thread that was executed on as a part of …\nThe ID of the thread that was run.\nThe ID of the tool call in the <code>required_action</code> object …\nThe ID of the tool call in the <code>required_action</code> object …\nAn array of tool calls the run step was involved in. These …\nThe tool calls generated by the model, such as function …\nA list of tools for which the outputs are being submitted.\nOverride the tools the assistant can use for this run. …\nOverride the tools the assistant can use for this run. …\nA list of tools the model may call. Currently, only …\nA list of tool enabled on the assistant. There can be a …\nThe list of tools that the assistant used for this run.\nOverride the tools the assistant can use for this run. …\nOverride the tools the assistant can use for this run. …\nA list of tools the model may call. Currently, only …\nAn alternative to sampling with temperature, called …\nAn alternative to sampling with temperature, called …\nAn alternative to sampling with temperature, called …\nAn alternative to sampling with temperature, called …\nAn alternative to sampling with temperature, called …\nAn alternative to sampling with temperature, called …\nTotal number of tokens used in the request (prompt + …\nThe total number of tokens used by the request.\nThe total number of billable tokens processed by this …\nThe ID of an uploaded file that contains training data.\nThe ID of an uploaded file that contains training data.\nThe ID of an uploaded file that contains training data.\nThe ID of an uploaded file that contains training data.\nThe file ID used for training. You can retrieve the …\nAlways <code>text</code>.\nAlways <code>file_citation</code>.\nAlways <code>file_path</code>.\nAlways <code>image_file</code>.\nFor now, this is always <code>submit_tool_outputs</code>.\nThe type of tool call the output is required for. For now, …\nThe type of run step, which can be either <code>message_creation</code> …\nAlways <code>message_creation</code>.\nAlways <code>tool_calls</code>.\nThe type of tool call. This is always going to be …\nAlways <code>logs</code>.\nAlways <code>image</code>.\nThe type of tool call. This is always going to be <code>retrieval</code>…\nThe type of tool call. This is always going to be <code>function</code> …\nThe type of the tool. Currently, only <code>function</code> is …\nSetting to <code>json_object</code> enables JSON mode. This guarantees …\nThe type of the tool. Currently, only <code>function</code> is …\nThe type of the tool. Currently, only <code>function</code> is …\nEither a URL of the image or the base64 encoded image data.\nEither a URL of the image or the base64 encoded image data.\nThe usage information for the request.\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which can …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which will …\nA unique identifier representing your end-user, which can …\nThe ID of an uploaded file that contains validation data.\nThe ID of an uploaded file that contains validation data.\nThe ID of an uploaded file that contains validation data.\nThe ID of an uploaded file that contains validation data.\nThe file ID used for validation. You can retrieve the …\nThe data that makes up the text.\nContent that depicts death, violence, or physical injury.\nThe score for the category ‘violence’.\nContent that depicts death, violence, or physical injury …\nThe score for the category ‘violence/graphic’.\nThe voice to use when generating the audio. Supported …\nThe voice to use when generating the audio. Supported …")