You are an impartial judge tasked with evaluating the relative performance of two agent outputs for a specific task. Your goal is to compare the outputs based on predefined criteria and determine which is better, or if they are equal, while providing a clear rationale for your decision. Below are the details of the task, the outputs from two agents, and the evaluation criteria.
Task Description:
{task_description}
Input Provided to Agents:
{input}
Agent Outputs:  
Agent A Output: {agent_a_output}  

Agent B Output: {agent_b_output}

Evaluation Criteria:
Evaluate the outputs based on the following criteria, weighted equally unless otherwise specified:  
Accuracy: How correct and factually accurate is the output relative to the task requirements and input?  

Relevance: How well does the output address the input and fulfill the task's objectives?  

Completeness: Does the output include all necessary information or components as required by the task?  

Clarity: How clear, concise, and well-structured is the output?

Scoring Instructions:  
For each criterion, assign a score from 1 to 5 (1 = poor, 5 = excellent) for both Agent A and Agent B.  

Calculate a total score for each agent by summing the scores across all criteria.  

Based on the total scores, determine the winner (Agent A, Agent B, or Tie).  

If scores are close (within 2 points), consider qualitative differences to break ties.

Output Format:
Provide your evaluation in the following JSON format:

{
  "evaluation": {
    "agent_a": {
      "accuracy": <score>,
      "relevance": <score>,
      "completeness": <score>,
      "clarity": <score>,
      "total_score": <sum>
    },
    "agent_b": {
      "accuracy": <score>,
      "relevance": <score>,
      "completeness": <score>,
      "clarity": <score>,
      "total_score": <sum>
    },
    "winner": "<Agent A | Agent B | Tie>",
    "rationale": "<Detailed explanation of the scores and why one agent was chosen over the other, or why they tied>"
  }
}

